#pragma kernel LoadGrid
#pragma kernel InitParIndex
#pragma kernel AssignGrid
#include "ParticleStruct.cginc"
#include "GridStruct.cginc"

RWStructuredBuffer<Particle> particleBuffer;
RWStructuredBuffer<Grid> gridBuffer;

int numParticles; // index trick
float3 gridLowCorner;
float3 gridHighCorner;
float gridSize;
int3 gridDimension; 
[numthreads(1,1,1)]
void InitParIndex (uint3 id : SV_DispatchThreadID)
{
	// Calculate grid index for each particle.
	uint3 pidx;
	int x,y,z;
	float3 particleOffset = particleBuffer[id.x].position - gridLowCorner;
	x = floor(particleOffset.x / gridSize);
	y = floor(particleOffset.y / gridSize);
	z = floor(particleOffset.z / gridSize);
	//outbound handle
	if(x < 0){ x = 0;}
	if(y < 0){ y = 0;}
	if(z < 0){ z = 0;}

	if(x > gridDimension.x) {x = gridDimension.x;}
	if(y > gridDimension.y) {y = gridDimension.y;}
	if(z > gridDimension.z) {z = gridDimension.z;}
	//write back
	pidx.x = x;
	pidx.y = y;
	pidx.z = z;
	particleBuffer[id.x].gridIndex = pidx;
	//particleIndexBuffer[id.x] = pidx;
}


[numthreads(64,1,1)]
void LoadGrid (uint3 g_id : SV_GroupID, uint3 id : SV_GroupThreadID)
{
    // Dispatch and initialize grids.
	// idx = numParticles means this pass hasn't been written to
	gridBuffer[g_id.x * 64 * 64 + g_id.y * 64 + id.x].PbIndex[0] = numParticles;
	gridBuffer[g_id.x * 64 * 64 + g_id.y * 64 + id.x].PbIndex[1] = numParticles;
	gridBuffer[g_id.x * 64 * 64 + g_id.y * 64 + id.x].PbIndex[2] = numParticles;
	gridBuffer[g_id.x * 64 * 64 + g_id.y * 64 + id.x].PbIndex[3] = numParticles;
	//gridBuffer[id.x].PbIndex[0] = groupThreadID.x;
	/*gridBuffer[id.x].PbIndex[0] = numParticles;
	gridBuffer[id.x].PbIndex[1] = numParticles;
	gridBuffer[id.x].PbIndex[2] = numParticles;
	gridBuffer[id.x].PbIndex[3] = numParticles;*/
}

uint passNum; // Pass index. Each frame we should run this from 0 to 3.
[numthreads(1,1,1)]
void AssignGrid (uint3 id : SV_DispatchThreadID)
{
	// TODO: Read data from particleIndexBuffer and try write
	// Must use atomic operations... Grids are shared by all threads.
	// How exactly? Might need 4 passes. Rach time we only write one pass in the grid struct atomically.
	// From the second pass on, check if the thread id is the same as the grid's previous passes. If same, return directly, otherwise write into the corresponding values.
	// There could be overflows, like 5+ particles in a same grid, but according to GPU Gems 3.29 this will rarely happen so it's okay to ignore this condition. 
	



	uint grid_x = particleBuffer[id.x].gridIndex.x;
	uint grid_y = particleBuffer[id.x].gridIndex.y;
	uint grid_z = particleBuffer[id.x].gridIndex.z;

	uint grid_idx = 64 * 64 * grid_x + 64 * grid_y + grid_z;

	
	if (gridBuffer[grid_idx].PbIndex[0] == numParticles) {
		gridBuffer[grid_idx].PbIndex[0] = id.x;
		return;
	}
	


	if (gridBuffer[grid_idx].PbIndex[1] == numParticles) {
		gridBuffer[grid_idx].PbIndex[1] = id.x;
		return;
	}
	

	
	if (gridBuffer[grid_idx].PbIndex[2] == numParticles) {
		gridBuffer[grid_idx].PbIndex[2] = id.x;
		return;
	}
	

	
	if (gridBuffer[grid_idx].PbIndex[3] == numParticles) {
		gridBuffer[grid_idx].PbIndex[3] = id.x;
		return;
	}
	


	

}